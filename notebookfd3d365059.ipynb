{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":377107,"sourceType":"datasetVersion","datasetId":165566}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n\n# IGNORING UNNECESSARRY WARNINGS\n\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:37:32.863844Z","iopub.execute_input":"2024-01-01T04:37:32.864364Z","iopub.status.idle":"2024-01-01T04:37:32.871738Z","shell.execute_reply.started":"2024-01-01T04:37:32.864326Z","shell.execute_reply":"2024-01-01T04:37:32.870587Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"No_Data_Path = Path(\"/kaggle/input/brain-mri-images-for-brain-tumor-detection/no\")\nYes_Data_Path = Path(\"/kaggle/input/brain-mri-images-for-brain-tumor-detection/yes\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:37:33.879810Z","iopub.execute_input":"2024-01-01T04:37:33.880286Z","iopub.status.idle":"2024-01-01T04:37:33.886173Z","shell.execute_reply.started":"2024-01-01T04:37:33.880242Z","shell.execute_reply":"2024-01-01T04:37:33.884820Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"No_JPG_Path = list(No_Data_Path.glob(r\"*.jpg\"))\nYes_JPG_Path = list(Yes_Data_Path.glob(r\"*.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:40:47.306466Z","iopub.execute_input":"2024-01-01T04:40:47.306985Z","iopub.status.idle":"2024-01-01T04:40:47.405370Z","shell.execute_reply.started":"2024-01-01T04:40:47.306947Z","shell.execute_reply":"2024-01-01T04:40:47.404301Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"JPG_Path_List = []\nJPG_Labels = []\n\nfor No_JPG in No_JPG_Path:\n    JPG_Path_List.append(str(No_JPG))\n    JPG_Labels.append('No') \n    \nfor Yes_JPG in Yes_JPG_Path:\n    JPG_Path_List.append(str(Yes_JPG))\n    JPG_Labels.append('Yes') ","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:43:39.053405Z","iopub.execute_input":"2024-01-01T04:43:39.054680Z","iopub.status.idle":"2024-01-01T04:43:39.062630Z","shell.execute_reply.started":"2024-01-01T04:43:39.054621Z","shell.execute_reply":"2024-01-01T04:43:39.061155Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"Main_Train_Data = pd.DataFrame({\n    'JPG': JPG_Path_List,\n    'TUMOR_CATEGORY': JPG_Labels\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:43:40.038967Z","iopub.execute_input":"2024-01-01T04:43:40.039441Z","iopub.status.idle":"2024-01-01T04:43:40.045357Z","shell.execute_reply.started":"2024-01-01T04:43:40.039406Z","shell.execute_reply":"2024-01-01T04:43:40.044374Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    Main_Train_Data['JPG'],\n    Main_Train_Data['TUMOR_CATEGORY'],\n    test_size=0.2,\n    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:43:41.254206Z","iopub.execute_input":"2024-01-01T04:43:41.254682Z","iopub.status.idle":"2024-01-01T04:43:41.263042Z","shell.execute_reply.started":"2024-01-01T04:43:41.254644Z","shell.execute_reply":"2024-01-01T04:43:41.261627Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.resize(img, (224, 224))  \n    img = img / 255.0  \n    return img","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:43:41.832285Z","iopub.execute_input":"2024-01-01T04:43:41.832831Z","iopub.status.idle":"2024-01-01T04:43:41.838833Z","shell.execute_reply.started":"2024-01-01T04:43:41.832778Z","shell.execute_reply":"2024-01-01T04:43:41.837880Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=Main_Train_Data,\n    x_col='JPG',\n    y_col='TUMOR_CATEGORY',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    subset='training',\n    seed=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:43:42.289178Z","iopub.execute_input":"2024-01-01T04:43:42.289666Z","iopub.status.idle":"2024-01-01T04:43:42.412415Z","shell.execute_reply.started":"2024-01-01T04:43:42.289629Z","shell.execute_reply":"2024-01-01T04:43:42.411183Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 171 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:43:46.678514Z","iopub.execute_input":"2024-01-01T04:43:46.679000Z","iopub.status.idle":"2024-01-01T04:43:47.162426Z","shell.execute_reply.started":"2024-01-01T04:43:46.678961Z","shell.execute_reply":"2024-01-01T04:43:47.161399Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_data, validation_data = train_test_split(\n    Main_Train_Data,\n    test_size=0.2,\n    random_state=42\n)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_data,\n    x_col='JPG',\n    y_col='TUMOR_CATEGORY',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    seed=42\n)\n\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    dataframe=validation_data,\n    x_col='JPG',\n    y_col='TUMOR_CATEGORY',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False  \n)\n\nhistory = model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=validation_generator\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:45:48.318157Z","iopub.execute_input":"2024-01-01T04:45:48.319525Z","iopub.status.idle":"2024-01-01T04:47:26.341566Z","shell.execute_reply.started":"2024-01-01T04:45:48.319476Z","shell.execute_reply":"2024-01-01T04:47:26.340011Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Found 136 validated image filenames belonging to 2 classes.\nFound 35 validated image filenames belonging to 2 classes.\nEpoch 1/10\n5/5 [==============================] - 11s 2s/step - loss: 3.1614 - accuracy: 0.5000 - val_loss: 1.0236 - val_accuracy: 0.5143\nEpoch 2/10\n5/5 [==============================] - 9s 2s/step - loss: 0.6594 - accuracy: 0.6618 - val_loss: 0.6215 - val_accuracy: 0.6000\nEpoch 3/10\n5/5 [==============================] - 8s 2s/step - loss: 0.6398 - accuracy: 0.6176 - val_loss: 0.5399 - val_accuracy: 0.6857\nEpoch 4/10\n5/5 [==============================] - 8s 1s/step - loss: 0.6079 - accuracy: 0.6838 - val_loss: 0.5258 - val_accuracy: 0.7429\nEpoch 5/10\n5/5 [==============================] - 8s 2s/step - loss: 0.6309 - accuracy: 0.6618 - val_loss: 0.5417 - val_accuracy: 0.7143\nEpoch 6/10\n5/5 [==============================] - 8s 1s/step - loss: 0.5798 - accuracy: 0.6912 - val_loss: 0.5874 - val_accuracy: 0.7143\nEpoch 7/10\n5/5 [==============================] - 8s 1s/step - loss: 0.5495 - accuracy: 0.7279 - val_loss: 0.5292 - val_accuracy: 0.8286\nEpoch 8/10\n5/5 [==============================] - 8s 1s/step - loss: 0.4914 - accuracy: 0.7941 - val_loss: 0.5607 - val_accuracy: 0.8000\nEpoch 9/10\n5/5 [==============================] - 8s 1s/step - loss: 0.4544 - accuracy: 0.7868 - val_loss: 0.5993 - val_accuracy: 0.8000\nEpoch 10/10\n5/5 [==============================] - 8s 1s/step - loss: 0.4657 - accuracy: 0.8235 - val_loss: 0.5659 - val_accuracy: 0.8000\n","output_type":"stream"}]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=Main_Train_Data,\n    x_col='JPG',\n    y_col='TUMOR_CATEGORY',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False  \n)\n\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(\"Test Accuracy:\", test_acc)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:49:15.696331Z","iopub.execute_input":"2024-01-01T04:49:15.696866Z","iopub.status.idle":"2024-01-01T04:49:18.288377Z","shell.execute_reply.started":"2024-01-01T04:49:15.696830Z","shell.execute_reply":"2024-01-01T04:49:18.287517Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Found 171 validated image filenames belonging to 2 classes.\n6/6 [==============================] - 2s 343ms/step - loss: 0.3986 - accuracy: 0.8421\nTest Accuracy: 0.8421052694320679\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-01T04:32:15.163130Z","iopub.status.idle":"2024-01-01T04:32:15.163926Z","shell.execute_reply.started":"2024-01-01T04:32:15.163681Z","shell.execute_reply":"2024-01-01T04:32:15.163704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}